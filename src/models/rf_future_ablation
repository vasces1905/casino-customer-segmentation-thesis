#!/usr/bin/env python3
"""
Feature Ablation Study - Segmentation Contribution Analysis
=========================================================
ChatGPT Recommendation: "Segmentasyon özelliklerinin model başarısına etkisini gösterir"

Academic Purpose:
- Validate segmentation features contribution
- Quantify feature importance scientifically  
- Justify clean data integration approach
"""

import numpy as np
import pandas as pd
import psycopg2
import logging
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, roc_auc_score
import joblib
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class FeatureAblationStudy:
    """
    Academic feature ablation study for segmentation validation
    ChatGPT: "Feature importance sonuçlarını bilimsel olarak doğrular"
    """
    
    def __init__(self, period_id: str = '2022-H1'):
        self.period_id = period_id
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.baseline_performance = None
        self.ablation_results = {}
        
        # Define feature groups for systematic ablation
        self.feature_groups = {
            'behavioral_basic': [
                'total_bet', 'avg_bet', 'loss_rate', 'total_sessions'
            ],
            'behavioral_advanced': [
                'days_since_last_visit', 'session_duration_volatility',
                'loss_chasing_score', 'sessions_last_30d', 'bet_trend_ratio'
            ],
            'segmentation_core': [
                'kmeans_cluster_id', 'kmeans_segment_encoded', 
                'segment_avg_session', 'silhouette_score'
            ],
            'segmentation_derived': [
                'personal_vs_segment_ratio', 'is_high_value', 
                'segment_outperformer'
            ],
            'risk_features': [
                'risk_score', 'needs_attention'
            ],
            'engagement_features': [
                'value_tier', 'engagement_level'
            ]
        }
    
    def load_clean_data_with_features(self):
        """Load clean data with all feature engineering"""
        logger.info(f"Loading data for ablation study ({self.period_id})...")
        
        conn = psycopg2.connect(
            host="localhost",
            database="casino_research",
            user="researcher",
            password="academic_password_2024"
        )
        
        query = f"""
        SELECT 
            cf.customer_id,
            cf.total_bet, cf.avg_bet, cf.loss_rate, cf.total_sessions,
            cf.days_since_last_visit, cf.session_duration_volatility,
            cf.loss_chasing_score, cf.sessions_last_30d, cf.bet_trend_ratio,
            ks.cluster_id as kmeans_cluster_id,
            ks.cluster_label as kmeans_segment,
            ks.silhouette_score,
            ks.avg_session_from_metadata as segment_avg_session
        FROM casino_data.customer_features cf
        INNER JOIN casino_data.kmeans_segments ks 
            ON cf.customer_id = ks.customer_id 
            AND cf.analysis_period = ks.period_id
        WHERE cf.analysis_period = '{self.period_id}'
            AND cf.total_bet > 0
            AND cf.total_bet <= 1500000
            AND ks.kmeans_version = 2
        ORDER BY cf.customer_id
        """
        
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        # Create all enhanced features
        df_enhanced = self._create_all_features(df)
        df_labeled = self._create_labels(df_enhanced)
        
        logger.info(f"Loaded {len(df_labeled)} customers with full feature set")
        return df_labeled
    
    def _create_all_features(self, df):
        """Create all enhanced features for ablation study"""
        df_enhanced = df.copy()
        
        # Segmentation encoding
        segment_hierarchy = {
            'Casual_Player': 1, 'Regular_Player': 2, 
            'High_Value_Player': 3, 'At_Risk_Player': 0
        }
        df_enhanced['kmeans_segment_encoded'] = df_enhanced['kmeans_segment'].map(segment_hierarchy).fillna(1)
        
        # Segmentation derived features
        df_enhanced['personal_vs_segment_ratio'] = (
            df_enhanced['total_bet'] / df_enhanced['segment_avg_session'].replace(0, 1)
        ).fillna(1.0)
        
        df_enhanced['segment_outperformer'] = (df_enhanced['personal_vs_segment_ratio'] > 1.5).astype(int)
        
        # Risk features
        df_enhanced['risk_score'] = (
            df_enhanced['loss_chasing_score'] * 0.3 +
            (df_enhanced['loss_rate'] > 25).astype(int) * 20 +
            (df_enhanced['days_since_last_visit'] > 60).astype(int) * 15
        )
        df_enhanced['needs_attention'] = (df_enhanced['risk_score'] > 30).astype(int)
        
        # Engagement features
        df_enhanced['value_tier'] = pd.cut(
            df_enhanced['total_bet'], bins=[0, 500, 2000, 10000, float('inf')],
            labels=[0, 1, 2, 3]
        ).astype(int)
        
        df_enhanced['engagement_level'] = pd.cut(
            df_enhanced['total_sessions'], bins=[0, 2, 5, 15, float('inf')],
            labels=[0, 1, 2, 3]
        ).astype(int)
        
        # High value flag
        df_enhanced['is_high_value'] = (df_enhanced['kmeans_segment_encoded'] >= 2).astype(int)
        
        return df_enhanced
    
    def _create_labels(self, df):
        """Create balanced labels for ablation study"""
        labels = []
        np.random.seed(42)
        
        for _, customer in df.iterrows():
            risk_prob = min(customer['risk_score'] / 100, 0.9)
            value_prob = customer['kmeans_segment_encoded'] / 3
            engagement_prob = min(customer['total_sessions'] / 20, 1.0)
            
            if risk_prob > 0.6:
                label = 'INTERVENTION_NEEDED'
            elif value_prob > 0.7 and engagement_prob > 0.5 and risk_prob < 0.3:
                label = 'HIGH_VALUE_TIER'
            elif value_prob > 0.4 and customer['personal_vs_segment_ratio'] > 1.1:
                label = 'GROWTH_TARGET'
            elif engagement_prob > 0.15 and risk_prob < 0.5:
                label = 'STANDARD_PROMO'
            elif engagement_prob < 0.2 or risk_prob > 0.7:
                label = 'LOW_ENGAGEMENT'
            else:
                label = 'NO_PROMOTION'
            
            labels.append(label)
        
        df['target_label'] = labels
        return df
    
    def run_baseline_full_features(self, df):
        """Establish baseline performance with all features"""
        logger.info("Establishing baseline performance (all features)...")
        
        # Get all features
        all_features = []
        for feature_group in self.feature_groups.values():
            all_features.extend(feature_group)
        
        # Prepare data
        X = df[all_features].fillna(0)
        y = df['target_label']
        
        # Train model
        performance = self._evaluate_feature_set(X, y, "ALL_FEATURES")
        self.baseline_performance = performance
        
        logger.info(f"Baseline: Acc={performance['accuracy']:.4f}, ROC={performance['roc_auc_macro']:.4f}")
        return performance
    
    def run_ablation_study(self, df):
        """Run systematic feature ablation study"""
        logger.info("Running systematic feature ablation study...")
        
        # 1. Individual feature group ablation
        logger.info("\nINDIVIDUAL FEATURE GROUP ABLATION:")
        
        for group_name, group_features in self.feature_groups.items():
            logger.info(f"   Testing without {group_name}...")
            
            # Create feature set without this group
            remaining_features = []
            for other_group, other_features in self.feature_groups.items():
                if other_group != group_name:
                    remaining_features.extend(other_features)
            
            # Evaluate
            X = df[remaining_features].fillna(0)
            y = df['target_label']
            
            performance = self._evaluate_feature_set(X, y, f"WITHOUT_{group_name.upper()}")
            self.ablation_results[f"without_{group_name}"] = {
                'performance': performance,
                'removed_features': group_features,
                'remaining_features': remaining_features,
                'feature_count': len(remaining_features)
            }
        
        # 2. Segmentation-only model
        logger.info("\nSEGMENTATION-ONLY MODEL:")
        seg_features = self.feature_groups['segmentation_core'] + self.feature_groups['segmentation_derived']
        X_seg = df[seg_features].fillna(0)
        y = df['target_label']
        
        seg_performance = self._evaluate_feature_set(X_seg, y, "SEGMENTATION_ONLY")
        self.ablation_results['segmentation_only'] = {
            'performance': seg_performance,
            'features': seg_features,
            'feature_count': len(seg_features)
        }
        
        # 3. Behavioral-only model  
        logger.info("\nBEHAVIORAL-ONLY MODEL:")
        behav_features = self.feature_groups['behavioral_basic'] + self.feature_groups['behavioral_advanced']
        X_behav = df[behav_features].fillna(0)
        
        behav_performance = self._evaluate_feature_set(X_behav, y, "BEHAVIORAL_ONLY")
        self.ablation_results['behavioral_only'] = {
            'performance': behav_performance,
            'features': behav_features,
            'feature_count': len(behav_features)
        }
        
        return self.ablation_results
    
    def _evaluate_feature_set(self, X, y, feature_set_name):
        """Evaluate model performance with given feature set"""
        # Encode labels
        y_encoded = self.label_encoder.fit_transform(y)
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
        )
        
        # Scale features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Train Random Forest
        rf = RandomForestClassifier(
            n_estimators=100, max_depth=10, random_state=42,
            min_samples_split=8, min_samples_leaf=4
        )
        rf.fit(X_train_scaled, y_train)
        
        # Evaluate
        y_pred = rf.predict(X_test_scaled)
        accuracy = accuracy_score(y_test, y_pred)
        
        # Cross-validation
        cv_scores = cross_val_score(rf, X_train_scaled, y_train, cv=5)
        
        # ROC AUC
        try:
            y_pred_proba = rf.predict_proba(X_test_scaled)
            roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='macro')
        except:
            roc_auc = 0.0
        
        performance = {
            'accuracy': accuracy,
            'roc_auc_macro': roc_auc,
            'cv_score': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'feature_set': feature_set_name
        }
        
        return performance
    
    def generate_ablation_report(self):
        """Generate comprehensive ablation study report"""
        if not self.baseline_performance or not self.ablation_results:
            logger.error("Run ablation study first")
            return None
        
        print("\n" + "="*80)
        print(f"FEATURE ABLATION STUDY REPORT - {self.period_id}")
        print("="*80)
        print("ChatGPT Goal: Validate segmentation features scientific contribution")
        print("="*80)
        
        # Baseline performance
        baseline = self.baseline_performance
        print(f"\nBASELINE PERFORMANCE (ALL FEATURES):")
        print(f"   Accuracy: {baseline['accuracy']:.4f} ({baseline['accuracy']*100:.1f}%)")
        print(f"   ROC AUC: {baseline['roc_auc_macro']:.4f} ({baseline['roc_auc_macro']*100:.1f}%)")
        print(f"   CV Score: {baseline['cv_score']:.4f} +/- {baseline['cv_std']:.4f}")
        
        # Feature group ablation analysis
        print(f"\nFEATURE GROUP ABLATION ANALYSIS:")
        print(f"{'Feature Group':<20} {'Accuracy':<10} {'ROC AUC':<10} {'Impact':<15} {'Contribution':<15}")
        print("-" * 80)
        
        group_impacts = []
        
        for ablation_name, ablation_data in self.ablation_results.items():
            if 'without_' in ablation_name:
                group_name = ablation_name.replace('without_', '').upper()
                perf = ablation_data['performance']
                
                # Calculate impact (performance drop when removed)
                acc_impact = baseline['accuracy'] - perf['accuracy']
                roc_impact = baseline['roc_auc_macro'] - perf['roc_auc_macro']
                
                # Contribution percentage
                acc_contrib = (acc_impact / baseline['accuracy']) * 100 if baseline['accuracy'] > 0 else 0
                roc_contrib = (roc_impact / baseline['roc_auc_macro']) * 100 if baseline['roc_auc_macro'] > 0 else 0
                
                print(f"{group_name:<20} {perf['accuracy']:<10.4f} {perf['roc_auc_macro']:<10.4f} "
                      f"{acc_impact:>+7.4f} ({acc_contrib:>+5.1f}%) {roc_impact:>+7.4f} ({roc_contrib:>+5.1f}%)")
                
                group_impacts.append({
                    'group': group_name,
                    'accuracy_impact': acc_impact,
                    'roc_impact': roc_impact,
                    'accuracy_contribution': acc_contrib,
                    'roc_contribution': roc_contrib
                })
        
        # Find most important feature group
        if group_impacts:
            most_important = max(group_impacts, key=lambda x: x['accuracy_impact'])
            print(f"\nMOST CRITICAL FEATURE GROUP: {most_important['group']}")
            print(f"   Accuracy Impact: {most_important['accuracy_impact']:+.4f} ({most_important['accuracy_contribution']:+.1f}%)")
            print(f"   ROC AUC Impact: {most_important['roc_impact']:+.4f} ({most_important['roc_contribution']:+.1f}%)")
        
        # Segmentation-specific analysis
        print(f"\nSEGMENTATION CONTRIBUTION ANALYSIS:")
        
        # Segmentation-only performance
        if 'segmentation_only' in self.ablation_results:
            seg_only = self.ablation_results['segmentation_only']['performance']
            print(f"   Segmentation-Only Model:")
            print(f"     Accuracy: {seg_only['accuracy']:.4f} ({seg_only['accuracy']*100:.1f}%)")
            print(f"     ROC AUC: {seg_only['roc_auc_macro']:.4f} ({seg_only['roc_auc_macro']*100:.1f}%)")
        
        # Behavioral-only performance
        if 'behavioral_only' in self.ablation_results:
            behav_only = self.ablation_results['behavioral_only']['performance']
            print(f"   Behavioral-Only Model:")
            print(f"     Accuracy: {behav_only['accuracy']:.4f} ({behav_only['accuracy']*100:.1f}%)")
            print(f"     ROC AUC: {behav_only['roc_auc_macro']:.4f} ({behav_only['roc_auc_macro']*100:.1f}%)")
            
            # Segmentation vs Behavioral comparison
            if 'segmentation_only' in self.ablation_results:
                seg_only = self.ablation_results['segmentation_only']['performance']
                seg_advantage_acc = seg_only['accuracy'] - behav_only['accuracy']
                seg_advantage_roc = seg_only['roc_auc_macro'] - behav_only['roc_auc_macro']
                
                print(f"\nSEGMENTATION vs BEHAVIORAL COMPARISON:")
                print(f"   Segmentation Advantage (Accuracy): {seg_advantage_acc:+.4f}")
                print(f"   Segmentation Advantage (ROC AUC): {seg_advantage_roc:+.4f}")
                
                if seg_advantage_acc > 0:
                    print(f"   RESULT: Segmentation features outperform behavioral features alone")
                else:
                    print(f"   RESULT: Behavioral features stronger than segmentation alone")
        
        # Academic conclusions
        print(f"\nACADEMIC CONCLUSIONS:")
        
        # Find segmentation impact
        seg_core_impact = next((g for g in group_impacts if 'SEGMENTATION_CORE' in g['group']), None)
        seg_derived_impact = next((g for g in group_impacts if 'SEGMENTATION_DERIVED' in g['group']), None)
        
        if seg_core_impact and seg_core_impact['accuracy_contribution'] > 1:
            print(f"   Segmentation core features contribute {seg_core_impact['accuracy_contribution']:.1f}% to accuracy")
            print(f"   Scientific validation: Segmentation integration justified")
        
        if seg_derived_impact and seg_derived_impact['accuracy_contribution'] > 1:
            print(f"   Derived segmentation features contribute {seg_derived_impact['accuracy_contribution']:.1f}% to accuracy")
            print(f"   Feature engineering: Personal vs segment ratios validated")
        
        # Overall segmentation contribution
        total_seg_contribution = 0
        if seg_core_impact:
            total_seg_contribution += seg_core_impact['accuracy_contribution']
        if seg_derived_impact:
            total_seg_contribution += seg_derived_impact['accuracy_contribution']
        
        print(f"\nTOTAL SEGMENTATION CONTRIBUTION: {total_seg_contribution:.1f}% of model accuracy")
        
        if total_seg_contribution > 5:
            print(f"   STRONG JUSTIFICATION: Segmentation features highly valuable")
        elif total_seg_contribution > 2:
            print(f"   MODERATE JUSTIFICATION: Segmentation features contribute meaningfully") 
        else:
            print(f"   MINIMAL JUSTIFICATION: Segmentation contribution limited")
        
        return group_impacts
    
    def save_ablation_results(self, output_dir: str = "models/ablation_study"):
        """Save ablation study results"""
        import os
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        results_path = f"{output_dir}/feature_ablation_{self.period_id}_{timestamp}.pkl"
        
        ablation_package = {
            'period_id': self.period_id,
            'baseline_performance': self.baseline_performance,
            'ablation_results': self.ablation_results,
            'feature_groups': self.feature_groups,
            'academic_metadata': {
                'purpose': 'Feature ablation study for segmentation validation',
                'methodology': 'Systematic feature group removal and evaluation',
                'academic_standard': 'Bath University MSc Business Analytics',
                'study_date': datetime.now().isoformat()
            }
        }
        
        joblib.dump(ablation_package, results_path)
        logger.info(f"Ablation study results saved: {results_path}")
        
        return results_path

def main():
    """Run feature ablation study"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Feature Ablation Study')
    parser.add_argument('--period', default='2022-H1', help='Period ID')
    parser.add_argument('--output_dir', default='models/ablation_study', help='Output directory')
    args = parser.parse_args()
    
    print("FEATURE ABLATION STUDY - SEGMENTATION VALIDATION")
    print("="*60)
    print("ChatGPT Goal: Scientifically validate segmentation contribution")
    print("="*60)
    
    # Initialize study
    study = FeatureAblationStudy(args.period)
    
    try:
        # Load data
        df = study.load_clean_data_with_features()
        
        # Establish baseline
        baseline = study.run_baseline_full_features(df)
        
        # Run ablation study
        ablation_results = study.run_ablation_study(df)
        
        # Generate report
        group_impacts = study.generate_ablation_report()
        
        # Save results
        results_path = study.save_ablation_results(args.output_dir)
        
        print(f"\nFEATURE ABLATION STUDY COMPLETED!")
        print(f"Results saved: {results_path}")
        
    except Exception as e:
        logger.error(f"Ablation study failed: {e}")
        raise

if __name__ == "__main__":
    main()